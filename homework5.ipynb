{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('text', 'r', encoding='utf-8') as f:\n",
    "    texts = f.read()\n",
    "    texts = texts.replace('\\ufeff', '') # убираем первый невидимый символ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "maxWordsCount = 1000\n",
    "tokenizer = Tokenizer(num_words=maxWordsCount, filters='!–\"—#$%&amp;()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n\\r«»',\n",
    "                       lower=True, split=' ', char_level=False)\n",
    "tokenizer.fit_on_texts([texts])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('1821', 1), ('1827', 1), ('г', 2), ('1', 8), ('озеро', 1), ('к', 64), ('меня', 26), ('на', 154), ('утре', 1), ('жизни', 9)]\n"
     ]
    }
   ],
   "source": [
    "dist = list(tokenizer.word_counts.items())\n",
    "print(dist[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tokenizer.texts_to_sequences([texts])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940, 1000)\n"
     ]
    }
   ],
   "source": [
    "res = keras.utils.to_categorical(data[0], num_classes=maxWordsCount)\n",
    "print( res.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "inp_words = 3\n",
    "n = res.shape[0]-inp_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8940,)\n"
     ]
    }
   ],
   "source": [
    "data = tokenizer.texts_to_sequences([texts])\n",
    "res = np.array( data[0] )\n",
    "print( res.shape )\n",
    " \n",
    "inp_words = 3\n",
    "n = res.shape[0]-inp_words\n",
    " \n",
    "X = np.array([res[i:i+inp_words] for i in range(n)])\n",
    "Y = keras.utils.to_categorical(res[inp_words:], num_classes=maxWordsCount)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 3, 512)            512000    \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 512)               524800    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1000)              513000    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,549,800\n",
      "Trainable params: 1,549,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(maxWordsCount, 512, input_length = inp_words))\n",
    "model.add(SimpleRNN(512, activation='tanh'))\n",
    "model.add(Dense(maxWordsCount, activation='softmax'))\n",
    "model.summary()\n",
    " \n",
    "model.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "280/280 [==============================] - 6s 16ms/step - loss: 6.2016 - accuracy: 0.0578\n",
      "Epoch 2/50\n",
      "280/280 [==============================] - 5s 16ms/step - loss: 5.4877 - accuracy: 0.0840\n",
      "Epoch 3/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 4.4635 - accuracy: 0.1502\n",
      "Epoch 4/50\n",
      "280/280 [==============================] - 5s 16ms/step - loss: 3.3974 - accuracy: 0.2379\n",
      "Epoch 5/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 2.5709 - accuracy: 0.3601\n",
      "Epoch 6/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 1.9774 - accuracy: 0.4862\n",
      "Epoch 7/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 1.5225 - accuracy: 0.6006\n",
      "Epoch 8/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 1.1807 - accuracy: 0.6862\n",
      "Epoch 9/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.9447 - accuracy: 0.7530\n",
      "Epoch 10/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.7445 - accuracy: 0.8077\n",
      "Epoch 11/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.6051 - accuracy: 0.8520\n",
      "Epoch 12/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.5002 - accuracy: 0.8798\n",
      "Epoch 13/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.4194 - accuracy: 0.9035\n",
      "Epoch 14/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.3709 - accuracy: 0.9197\n",
      "Epoch 15/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.3285 - accuracy: 0.9342\n",
      "Epoch 16/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2883 - accuracy: 0.9428\n",
      "Epoch 17/50\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.2677 - accuracy: 0.9470\n",
      "Epoch 18/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2496 - accuracy: 0.9538\n",
      "Epoch 19/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2382 - accuracy: 0.9537\n",
      "Epoch 20/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2372 - accuracy: 0.9552\n",
      "Epoch 21/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2325 - accuracy: 0.9550\n",
      "Epoch 22/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2320 - accuracy: 0.9568\n",
      "Epoch 23/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2188 - accuracy: 0.9576\n",
      "Epoch 24/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2255 - accuracy: 0.9580\n",
      "Epoch 25/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2202 - accuracy: 0.9564\n",
      "Epoch 26/50\n",
      "280/280 [==============================] - 5s 16ms/step - loss: 0.2412 - accuracy: 0.9520\n",
      "Epoch 27/50\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.2269 - accuracy: 0.9551\n",
      "Epoch 28/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2241 - accuracy: 0.9560\n",
      "Epoch 29/50\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.2084 - accuracy: 0.9571\n",
      "Epoch 30/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1989 - accuracy: 0.9594\n",
      "Epoch 31/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1902 - accuracy: 0.9637\n",
      "Epoch 32/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1855 - accuracy: 0.9642\n",
      "Epoch 33/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1848 - accuracy: 0.9639\n",
      "Epoch 34/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1773 - accuracy: 0.9652\n",
      "Epoch 35/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2004 - accuracy: 0.9602\n",
      "Epoch 36/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.2012 - accuracy: 0.9624\n",
      "Epoch 37/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1906 - accuracy: 0.9630\n",
      "Epoch 38/50\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.1774 - accuracy: 0.9655\n",
      "Epoch 39/50\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.1804 - accuracy: 0.9640\n",
      "Epoch 40/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1812 - accuracy: 0.9634\n",
      "Epoch 41/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1743 - accuracy: 0.9642\n",
      "Epoch 42/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1817 - accuracy: 0.9640\n",
      "Epoch 43/50\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.1869 - accuracy: 0.9618\n",
      "Epoch 44/50\n",
      "280/280 [==============================] - 5s 18ms/step - loss: 0.1895 - accuracy: 0.9630\n",
      "Epoch 45/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1895 - accuracy: 0.9622\n",
      "Epoch 46/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1798 - accuracy: 0.9649\n",
      "Epoch 47/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1638 - accuracy: 0.9671\n",
      "Epoch 48/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1752 - accuracy: 0.9641\n",
      "Epoch 49/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1639 - accuracy: 0.9665\n",
      "Epoch 50/50\n",
      "280/280 [==============================] - 5s 17ms/step - loss: 0.1712 - accuracy: 0.9659\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X, Y, batch_size=32, epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def buildPhrase(texts, str_len = 20):\n",
    "  res = texts\n",
    "  tokenizer.fit_on_texts([texts])\n",
    "  data = tokenizer.texts_to_sequences([texts])[0]\n",
    "  for i in range(str_len):\n",
    "    x = data[i: i+inp_words]\n",
    "    inp = np.expand_dims(x, axis=0)\n",
    " \n",
    "    pred = model.predict( inp ) # предсказываем OHE четвертого символа\n",
    "    indx = pred.argmax(axis=1)[0]\n",
    "    data.append(indx)\n",
    " \n",
    "    res += \" \" + tokenizer.index_word[indx] # дописываем строку\n",
    " \n",
    "  return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 210ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "позитив добавляет годы шепчут ангелы ли бред как будто в огне и сказал ли бред как будто в огне и сказал ли бред\n"
     ]
    }
   ],
   "source": [
    "res = buildPhrase(\"позитив добавляет годы\")\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 166ms/step\n",
      "1/1 [==============================] - 0s 162ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 51ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 52ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 42ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 47ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 31ms/step\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      " ангел мощный былом! мной предо ли тени неведомой были да не прошли в всей видений в что я тщетно что как древней грудь \n",
      "  пережить кто и долг там где люди на не сердца ты бег со себе взгляд и не пустыне так молний светла чара не \n",
      "  рай. гирлянда и луна всегда не ах на вовек сердца в дня и в том скользит тобой ветер то моря на даже плащ \n",
      "  к Печаль грез как рой плывет лет в видишь чтоб не айрина айрина могила красота покой окно на мир ночной увы спит с \n",
      "  мной белели Вот во сне было сном все друг во мгле иль днем в дождь иль нет но идут смел как бред все \n",
      "  нахмурит мертв! -- планет прочь не его на спадали поднятые роз бросая как ответ дианы во звезд был тех что за море конца \n",
      " \n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    " \n",
    " \n",
    "def mygen(s: str, n: int):\n",
    "    for _ in range(n):\n",
    "        yield choice(s.split())\n",
    "\n",
    "\n",
    "\n",
    "m=\"\"\n",
    "for i in range(6):\n",
    "    \n",
    "    res = buildPhrase(next(mygen(texts, 1))+\" \" +next(mygen(texts, 1))+\" \" +next(mygen(texts, 1)))\n",
    "    m+=\" \"+res+\" \\n \"\n",
    "print(m)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
