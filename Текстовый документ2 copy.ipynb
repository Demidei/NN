{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "4IgnCZuOs4Fk"
      },
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from skimage import io\n",
        "import os\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "-9AAwHnPr7od"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "data_r = zipfile.ZipFile('train.zip', 'r')\n",
        "data_r.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "QNsrrl6VsU_F"
      },
      "outputs": [],
      "source": [
        "data_r = zipfile.ZipFile('test.zip', 'r')\n",
        "data_r.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "SISIsfkxs5l7"
      },
      "outputs": [],
      "source": [
        "def download_data(path):\n",
        "  data = []\n",
        "  for path_image in sorted(os.listdir(path=path)):\n",
        "    image = Image.open(path + path_image) #РћС‚РєСЂС‹РІР°РµРј РёР·РѕР±СЂР°Р¶РµРЅРёРµ.\n",
        "    data.append(np.array(image)) #Р—Р°РіСЂСѓР¶Р°РµРј РїРёРєСЃРµР»Рё.\n",
        "  return data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aVma1xbgs2jF"
      },
      "outputs": [],
      "source": [
        "X_train = download_data(r\"train/images/\")\n",
        "Y_train = download_data(r\"train/masks/\")\n",
        "X_test = download_data(r\"test/images/\")\n",
        "Y_test = download_data(r\"test/masks/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "X_ayb_KzU-sY"
      },
      "outputs": [],
      "source": [
        "def resize(input_image, input_mask):\n",
        "   input_image = tf.image.resize(input_image, (128, 128), method=\"nearest\")\n",
        "   input_mask = tf.image.resize(input_mask, (128, 128), method=\"nearest\")\n",
        "   return input_image, input_mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "K4OM3WxRVBCF"
      },
      "outputs": [],
      "source": [
        "X_train, Y_train = resize(X_train, Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "X8Tl2Ee4VH9l"
      },
      "outputs": [],
      "source": [
        "X_test, Y_test = resize(X_test, Y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 683
        },
        "id": "5fOK8rmVt0ak",
        "outputId": "75649d54-0e0c-4e82-86e8-d3faa9f4cddb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(128, 128, 3), dtype=int32, numpy=\n",
              "array([[[238, 241, 246],\n",
              "        [185, 190, 196],\n",
              "        [249, 255, 255],\n",
              "        ...,\n",
              "        [178, 177, 185],\n",
              "        [220, 219, 225],\n",
              "        [235, 237, 250]],\n",
              "\n",
              "       [[254, 255, 255],\n",
              "        [252, 255, 255],\n",
              "        [250, 251, 253],\n",
              "        ...,\n",
              "        [213, 209, 223],\n",
              "        [199, 192, 199],\n",
              "        [152, 145, 152]],\n",
              "\n",
              "       [[194, 194, 196],\n",
              "        [239, 238, 243],\n",
              "        [253, 254, 255],\n",
              "        ...,\n",
              "        [ 96,  88, 101],\n",
              "        [157, 142, 149],\n",
              "        [148, 132, 133]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[213, 207, 217],\n",
              "        [238, 233, 239],\n",
              "        [211, 208, 219],\n",
              "        ...,\n",
              "        [247, 240, 234],\n",
              "        [218, 211, 203],\n",
              "        [241, 234, 224]],\n",
              "\n",
              "       [[231, 225, 235],\n",
              "        [166, 161, 167],\n",
              "        [211, 208, 219],\n",
              "        ...,\n",
              "        [255, 253, 250],\n",
              "        [237, 230, 222],\n",
              "        [223, 216, 208]],\n",
              "\n",
              "       [[246, 240, 250],\n",
              "        [198, 191, 198],\n",
              "        [199, 197, 208],\n",
              "        ...,\n",
              "        [240, 237, 230],\n",
              "        [249, 238, 232],\n",
              "        [255, 253, 243]]])>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrG-ykmIuOcj",
        "outputId": "33c47cf2-ad24-4014-a890-d4b4184d77e4"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "7"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCXQpzyZt6Ui",
        "outputId": "599cdd4b-b159-4092-a3ec-ed64958f4ae3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZcmg1WQuTIi",
        "outputId": "12985c79-0d80-422c-e911-f69be60e3bd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "128"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tI-7mKvJuixR",
        "outputId": "4105938f-2c23-4195-aa30-058272436cd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([132,  41, 246, 255])>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "Y_train[0][0][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMeBQA_suYnq",
        "outputId": "85185bf6-0107-426f-b3a6-8aaeb8ad71ce"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(Y_train[0][0][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "KC2UWCMGuwz4"
      },
      "outputs": [],
      "source": [
        "palette = {0 : (60, 16, 152), # Building\n",
        "           1 : (132, 41, 246), # Land\n",
        "           2 : (110, 193, 228), # Road\n",
        "           3 : (254, 221, 58), # Vegetation\n",
        "           4 : (226, 169, 41), # Water\n",
        "           5 : (155, 155, 155)} # Unlabeled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "XJGCusxYvIOi"
      },
      "outputs": [],
      "source": [
        "invert_palette = {v: k for k, v in palette.items()}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "u2xjpP2VvUiY"
      },
      "outputs": [],
      "source": [
        "# СЃРµРіРјРµРЅС‚Р°С†РёСЏ РЅРµР№СЂРѕРЅРЅРѕР№ СЃРµС‚Рё РІ RGB РёР·РѕР±СЂР°Р¶РµРЅРёРµ\n",
        "def convert_to_color(arr_2d, palette=palette):\n",
        "    \"\"\" Numeric labels to RGB-color encoding \"\"\"\n",
        "    arr_3d = np.zeros((arr_2d.shape[0], arr_2d.shape[1], 3), dtype=np.uint8)\n",
        "\n",
        "    for c, i in palette.items():\n",
        "        m = arr_2d == c\n",
        "        arr_3d[m] = i\n",
        "\n",
        "    return arr_3d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "7uyEDYdTv81I"
      },
      "outputs": [],
      "source": [
        "def convert_from_color(arr_3d, palette=invert_palette):\n",
        "    \"\"\" RGB-color encoding to grayscale labels \"\"\"\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.uint8)\n",
        "\n",
        "    arr_2d = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.int8) # РїСЂРёРЅР°РґР»РµР¶РЅРѕСЃС‚СЊ РєР°Р¶РґРѕРіРѕ РїРёРєСЃРµР»СЏ РєР»Р°СЃСЃСѓ\n",
        "    min_distance = np.zeros((arr_3d.shape[0], arr_3d.shape[1]), dtype=np.float32)+1000 # СЂР°СЃСЃС‚РѕСЏРЅРёРµ РґРѕ Р±Р»РёР¶Р°Р№С€РµРіРѕ РєР»Р°СЃСЃР° РґР»СЏ РїРёРєСЃРµР»РµР№\n",
        "    for c, i in palette.items():\n",
        "      distance = np.sum((arr_3d - np.array(c).reshape(1, 1, 3))**2, axis=-1)**(1/2) # РёС‰РµРј СЂР°СЃСЃС‚РѕСЏРЅРёРµ РґР»СЏ РєР°Р¶РґРѕРіРѕ РїРёРєСЃРµР»СЏ РґРѕ РїСЂРѕРІРµСЂСЏРµРјРѕРіРѕ РєР»Р°СЃСЃР° РїРѕ РµРІРєР»РёРґСѓ СЂР°СЃ-РёРµ\n",
        "      condition = min_distance > distance # РїРѕРёСЃРє СЌР»РµРјРµРЅС‚РѕРІ РјРµРЅСЊС€Рµ min_distance\n",
        "      min_distance[condition] = distance[condition] # Р·Р°РјРµРЅР° РґРёСЃС‚Р°РЅС†РёРё РЅР°Р№РґРµРЅРЅС‹С… СЌР»РµРјРµРЅС‚РѕРІ\n",
        "      arr_2d[condition] = i # Р·Р°РјРµРЅР° РєР»Р°СЃСЃР° РЅР°Р№РґРµРЅРЅС‹С… СЌР»РµРјРµРЅС‚РѕРІ\n",
        "\n",
        "    for c, i in palette.items():\n",
        "      m = np.all(arr_3d == np.array(c).reshape(1, 1, 3), axis=2)\n",
        "      arr_2d[m] = i\n",
        "\n",
        "    arr_2d = arr_2d.tolist()\n",
        "    for i in range(len(arr_2d)):\n",
        "      for j in range(len(arr_2d[0])):\n",
        "        label = [0, 0, 0, 0, 0, 0]\n",
        "        label[arr_2d[i][j]] = 1\n",
        "        arr_2d[i][j] = label\n",
        "    arr_2d = np.array(arr_2d)\n",
        "\n",
        "    return arr_2d"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QRH5wFPIxysn"
      },
      "outputs": [],
      "source": [
        "X_train_pred = np.array(X_train).reshape([7, 128, 128, 3])/255\n",
        "X_test_pred = np.array(X_test).reshape([2, 128, 128, 3])/255\n",
        "Y_train_pred = []\n",
        "for i in range(len(Y_train)):\n",
        "  Y_train_pred.append(convert_from_color(Y_train[i][:, :, :3]))\n",
        "Y_train_pred = np.array(Y_train_pred)\n",
        "Y_test_pred = []\n",
        "for i in range(len(Y_test)):\n",
        "  Y_test_pred.append(convert_from_color(Y_test[i][:, :, :3]))\n",
        "Y_test_pred = np.array(Y_test_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "S6xEqOpzyK4m"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras import *\n",
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "yw4chFWMT5JY"
      },
      "outputs": [],
      "source": [
        "def double_conv_block(x, n_filters):\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   # Conv2D then ReLU activation\n",
        "   x = layers.Conv2D(n_filters, 3, padding = \"same\", activation = \"relu\", kernel_initializer = \"he_normal\")(x)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "71aa1kS9UdpV"
      },
      "outputs": [],
      "source": [
        "def upsample_block(x, conv_features, n_filters):\n",
        "   # upsample\n",
        "   x = layers.Conv2DTranspose(n_filters, 3, 2, padding=\"same\")(x)\n",
        "   # concatenate\n",
        "   x = layers.concatenate([x, conv_features])\n",
        "   # dropout\n",
        "   x = layers.Dropout(0.3)(x)\n",
        "   # Conv2D twice with ReLU activation\n",
        "   x = double_conv_block(x, n_filters)\n",
        "   return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "6-0SlpZRT9JP"
      },
      "outputs": [],
      "source": [
        "def downsample_block(x, n_filters):\n",
        "   f = double_conv_block(x, n_filters)\n",
        "   p = layers.MaxPool2D(2)(f)\n",
        "   p = layers.Dropout(0.3)(p)\n",
        "   return f, p"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "FVTEl4lXUG_A"
      },
      "outputs": [],
      "source": [
        "def build_unet_model():\n",
        "   # inputs\n",
        "   inputs = layers.Input(shape=(128,128,3))\n",
        "   # encoder: contracting path - downsample\n",
        "   # 1 - downsample\n",
        "   f1, p1 = downsample_block(inputs, 64)\n",
        "   # 2 - downsample\n",
        "   f2, p2 = downsample_block(p1, 128)\n",
        "   # 3 - downsample\n",
        "   f3, p3 = downsample_block(p2, 256)\n",
        "   # 4 - downsample\n",
        "   f4, p4 = downsample_block(p3, 512)\n",
        "   # 5 - bottleneck\n",
        "   bottleneck = double_conv_block(p4, 1024)\n",
        "   # decoder: expanding path - upsample\n",
        "   # 6 - upsample\n",
        "   u6 = upsample_block(bottleneck, f4, 512)\n",
        "   # 7 - upsample\n",
        "   u7 = upsample_block(u6, f3, 256)\n",
        "   # 8 - upsample\n",
        "   u8 = upsample_block(u7, f2, 128)\n",
        "   # 9 - upsample\n",
        "   u9 = upsample_block(u8, f1, 64)\n",
        "   # outputs\n",
        "   outputs = layers.Conv2D(6, 1, padding=\"same\", activation = \"softmax\")(u9)\n",
        "   # unet model with Keras Functional API\n",
        "   unet_model = tf.keras.Model(inputs, outputs, name=\"U-Net\")\n",
        "   return unet_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Z3otCMTXUVsr"
      },
      "outputs": [],
      "source": [
        "unet_model = build_unet_model()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "bR8a8e6KVh86"
      },
      "outputs": [],
      "source": [
        "unet_model.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=\"accuracy\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAuxCsFsVlyZ",
        "outputId": "0cf5ddd9-2c74-4dc0-fff2-dffd166aab5c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9458 - accuracy: 0.6659 - val_loss: 0.8970 - val_accuracy: 0.7698\n",
            "Epoch 2/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9409 - accuracy: 0.6652 - val_loss: 0.9025 - val_accuracy: 0.7742\n",
            "Epoch 3/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9446 - accuracy: 0.6631 - val_loss: 0.9035 - val_accuracy: 0.7723\n",
            "Epoch 4/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9449 - accuracy: 0.6612 - val_loss: 0.8913 - val_accuracy: 0.7771\n",
            "Epoch 5/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9368 - accuracy: 0.6624 - val_loss: 0.8767 - val_accuracy: 0.7887\n",
            "Epoch 6/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9299 - accuracy: 0.6691 - val_loss: 0.8637 - val_accuracy: 0.8009\n",
            "Epoch 7/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9270 - accuracy: 0.6811 - val_loss: 0.8475 - val_accuracy: 0.8145\n",
            "Epoch 8/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9192 - accuracy: 0.6947 - val_loss: 0.8271 - val_accuracy: 0.8272\n",
            "Epoch 9/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9090 - accuracy: 0.7065 - val_loss: 0.8068 - val_accuracy: 0.8383\n",
            "Epoch 10/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.9013 - accuracy: 0.7132 - val_loss: 0.7825 - val_accuracy: 0.8422\n",
            "Epoch 11/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8952 - accuracy: 0.7149 - val_loss: 0.7484 - val_accuracy: 0.8432\n",
            "Epoch 12/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8838 - accuracy: 0.7145 - val_loss: 0.7116 - val_accuracy: 0.8438\n",
            "Epoch 13/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8716 - accuracy: 0.7149 - val_loss: 0.6754 - val_accuracy: 0.8446\n",
            "Epoch 14/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8620 - accuracy: 0.7162 - val_loss: 0.6378 - val_accuracy: 0.8448\n",
            "Epoch 15/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8487 - accuracy: 0.7168 - val_loss: 0.6044 - val_accuracy: 0.8440\n",
            "Epoch 16/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8328 - accuracy: 0.7188 - val_loss: 0.5851 - val_accuracy: 0.8415\n",
            "Epoch 17/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8199 - accuracy: 0.7207 - val_loss: 0.5717 - val_accuracy: 0.8380\n",
            "Epoch 18/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.8041 - accuracy: 0.7227 - val_loss: 0.5536 - val_accuracy: 0.8357\n",
            "Epoch 19/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7891 - accuracy: 0.7229 - val_loss: 0.5346 - val_accuracy: 0.8366\n",
            "Epoch 20/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7731 - accuracy: 0.7256 - val_loss: 0.5239 - val_accuracy: 0.8361\n",
            "Epoch 21/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7594 - accuracy: 0.7266 - val_loss: 0.5185 - val_accuracy: 0.8392\n",
            "Epoch 22/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7463 - accuracy: 0.7310 - val_loss: 0.5160 - val_accuracy: 0.8408\n",
            "Epoch 23/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7362 - accuracy: 0.7353 - val_loss: 0.5154 - val_accuracy: 0.8436\n",
            "Epoch 24/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7293 - accuracy: 0.7388 - val_loss: 0.5122 - val_accuracy: 0.8493\n",
            "Epoch 25/25\n",
            "1/1 [==============================] - 3s 3s/step - loss: 0.7240 - accuracy: 0.7417 - val_loss: 0.5014 - val_accuracy: 0.8547\n",
            "CPU times: total: 11min 58s\n",
            "Wall time: 1min 21s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "history = unet_model.fit(X_train_pred, Y_train_pred,  epochs=25, validation_data = (X_test_pred, Y_test_pred))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jyr6zavFBDdH"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
